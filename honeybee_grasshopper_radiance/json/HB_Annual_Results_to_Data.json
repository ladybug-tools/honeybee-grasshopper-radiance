{
  "version": "1.8.0", 
  "nickname": "AnnualToData", 
  "outputs": [
    [
      {
        "access": "None", 
        "name": "data", 
        "description": "A list of hourly data collections containing illuminance or irradiance results.\nThese can be visulized using the ladybug components or deconstructed\nfor detailed analysis with native Grasshopper math components.", 
        "type": null, 
        "default": null
      }
    ]
  ], 
  "inputs": [
    {
      "access": "list", 
      "name": "_results", 
      "description": "An list of annual Radiance result files from the \"HB Annual Daylight\"\ncomponent (containing the .ill files and the sun-up-hours.txt).\nThis can also be just the path to the folder containing these\nresult files.", 
      "type": "string", 
      "default": null
    }, 
    {
      "access": "list", 
      "name": "dyn_sch_", 
      "description": "Optional dynamic Aperture Group Schedules from the \"HB Aperture Group\nSchedule\" component, which will be used to customize the behavior\nof any dyanmic aperture geometry in the output metrics. If unsupplied,\nall dynamic aperture groups will be in their default state in for\nthe output metrics.", 
      "type": "System.Object", 
      "default": null
    }, 
    {
      "access": "list", 
      "name": "_sel_pts", 
      "description": "A point or list of points, which will be used to filter the sensors\nfor which data collections will be imported.", 
      "type": "Point3d", 
      "default": null
    }, 
    {
      "access": "tree", 
      "name": "_all_pts", 
      "description": "The data tree of all sensor points that were used in the simulation.\nThis is required in order to look up the index of the _sel_pts in\nthe results matrices.", 
      "type": "Point3d", 
      "default": null
    }, 
    {
      "access": "list", 
      "name": "sel_vecs_", 
      "description": "An optional vector or list of vectors, which will be used to filter\nthe sensors for which data collections will be imported. If there\nis an input here, the all_vecs_ must be connected.", 
      "type": "Vector3d", 
      "default": null
    }, 
    {
      "access": "tree", 
      "name": "all_vecs_", 
      "description": "The data tree of all sensor directions that were used in the simulation.\nThis is required in order to look up the index of the sel_vecs_ in\nthe results matrices.", 
      "type": "Vector3d", 
      "default": null
    }
  ], 
  "subcategory": "4 :: Results", 
  "code": "\nimport os\nimport json\nimport subprocess\n\ntry:\n    from ladybug.datatype.illuminance import Illuminance\n    from ladybug.datatype.energyflux import Irradiance\n    from ladybug.datatype.time import Time\n    from ladybug.datatype.fraction import Fraction\n    from ladybug.analysisperiod import AnalysisPeriod\n    from ladybug.header import Header\n    from ladybug.datacollection import HourlyContinuousCollection\n    from ladybug.futil import write_to_file\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import ladybug:\\n\\t{}'.format(e))\n\ntry:\n    from honeybee.config import folders\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import honeybee:\\n\\t{}'.format(e))\n\ntry:\n    from honeybee_radiance.postprocess.annualdaylight import _process_input_folder\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import honeybee_radiance:\\n\\t{}'.format(e))\n\ntry:\n    from honeybee_radiance_postprocess.dynamic import DynamicSchedule\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import honeybee_radiance:\\n\\t{}'.format(e))\n\ntry:\n    from ladybug_{{cad}}.config import tolerance\n    from ladybug_{{cad}}.togeometry import to_point3d, to_vector3d\n    from ladybug_{{cad}}.{{plugin}} import all_required_inputs, list_to_data_tree, \\\n        data_tree_to_list, give_warning\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import ladybug_{{cad}}:\\n\\t{}'.format(e))\n\n\ndef file_to_data(ill_file, point_filter, su_pattern, header, timestep, grid_id):\n    \"\"\"Get a list of data collections for a given result file.\"\"\"\n    data_colls = []\n    new_header = header.duplicate()\n    new_header.metadata['sensor grid'] = grid_id\n    with open(ill_file) as results:\n        if point_filter is None:\n            for pt_res in results:\n                base_values = [0] * 8760 * timestep\n                for val, hr in zip(pt_res.split(), su_pattern):\n                    base_values[hr] = float(val)\n                data_colls.append(HourlyContinuousCollection(new_header, base_values))\n        else:\n            for i, pt_res in enumerate(results):\n                if i in point_filter:\n                    new_header = new_header.duplicate()\n                    new_header.metadata['sensor index'] = i\n                    base_values = [0] * 8760 * timestep\n                    for val, hr in zip(pt_res.split(), su_pattern):\n                        base_values[hr] = float(val)\n                    data_colls.append(HourlyContinuousCollection(new_header, base_values))\n    return data_colls\n\n\ndef find_point_in_grid(s_pt, all_pts):\n    \"\"\"Find the index of a point in a list of list of grids.\"\"\"\n    m_pts = []\n    for i, grid_pts in enumerate(all_pts):\n        for j, g_pt in enumerate(grid_pts):\n            if g_pt.is_equivalent(s_pt, tolerance):\n                m_pts.append((i, j))\n    return m_pts\n\n\ndef find_vec_in_grid(s_v, all_vecs, pt_filter):\n    \"\"\"Find the index of a vector in a list of list of grids.\"\"\"\n    m_vecs = []\n    for i, grid in enumerate(pt_filter):\n        for j in grid:\n            if all_vecs[i][j].is_equivalent(s_v, tolerance):\n                m_vecs.append((i, j))\n    return m_vecs\n\n\nif all_required_inputs(ghenv.Component):\n    # get the relevant .ill files\n    res_folder = os.path.dirname(_results[0]) if os.path.isfile(_results[0]) \\\n        else _results[0]\n    grids, sun_up_hours = _process_input_folder(res_folder, '*')\n\n    # set up the sensor filter\n    pt_filter = [None for i in grids]\n    if len(_sel_pts) != 0 or len(sel_vecs_) != 0:\n        pt_filter = [[] for i in grids]\n\n    # check the sel_pts and all_pts input\n    if len(_sel_pts) != 0:\n        all_pts = [[to_point3d(pt) for pt in dat[-1]] for dat in data_tree_to_list(_all_pts)]\n        assert len(all_pts) != 0, '_all_pts must be connected in order to use _sel_pts.'\n        sel_pts = [to_point3d(pt) for pt in _sel_pts]\n        for s_pt in sel_pts:\n            m_pts = find_point_in_grid(s_pt, all_pts)\n            for i, j in m_pts:\n                pt_filter[i].append(j)\n\n    # check the sel_vecs and all_vecs input\n    if len(sel_vecs_) != 0:\n        new_pt_filter = [[] for i in grids]\n        all_vecs = [[to_vector3d(v) for v in dat[-1]] for dat in data_tree_to_list(all_vecs_)]\n        assert len(all_vecs) != 0, 'all_vecs_ must be connected in order to use sel_vecs_.'\n        sel_vecs = [to_vector3d(v) for v in sel_vecs_]\n        for s_v in sel_vecs:\n            m_vs = find_point_in_grid(s_v, all_vecs) if len(_sel_pts) == 0 else \\\n                find_vec_in_grid(s_v, all_vecs, pt_filter)\n            for i, j in m_vs:\n                new_pt_filter[i].append(j)\n        pt_filter = new_pt_filter\n\n    # check to see if results use the newer numpy arrays\n    if os.path.isdir(os.path.join(res_folder, '__static_apertures__'))  or \\\n            os.path.isfile(os.path.join(res_folder, 'grid_states.json')):\n        cmds = [folders.python_exe_path, '-m', 'honeybee_radiance_postprocess',\n                'post-process', 'annual-to-data', res_folder]\n        if pt_filter[0] is not None:\n            sen_dict = {g['full_id']: s_ind for g, s_ind in zip(grids, pt_filter)}\n            si_file = os.path.join(res_folder, 'sensor_indices.json')\n            write_to_file(si_file, json.dumps(sen_dict))\n            cmds.extend(['--sensor-index', si_file])\n        if len(dyn_sch_) != 0:\n            if os.path.isfile(os.path.join(res_folder, 'grid_states.json')):\n                dyn_sch = dyn_sch_[0] if isinstance(dyn_sch_[0], DynamicSchedule) else \\\n                    DynamicSchedule.from_group_schedules(dyn_sch_)\n                dyn_sch_file = dyn_sch.to_json(folder=res_folder)\n                cmds.extend(['--states', dyn_sch_file])\n            else:\n                msg = 'No dynamic aperture groups were found in the Model.\\n' \\\n                    'The input dynamic schedules will be ignored.'\n                print(msg)\n                give_warning(ghenv.Component, msg)\n        use_shell = True if os.name == 'nt' else False\n        custom_env = os.environ.copy()\n        custom_env['PYTHONHOME'] = ''\n        process = subprocess.Popen(\n            cmds, cwd=res_folder, shell=use_shell, env=custom_env,\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = process.communicate()  # wait for the process to finish\n        if stderr != '':\n            print(stderr)\n            raise ValueError('Failed to compute data collections.')\n        data_dicts = json.loads(stdout)\n        data = [[HourlyContinuousCollection.from_dict(d) for d in data]\n                for data in data_dicts]\n        data = list_to_data_tree(data)\n\n    else:\n        if len(dyn_sch_) != 0:\n            msg = 'Dynamic Schedules are currently only supported for Annual Daylight ' \\\n                'simulations.\\nThe input schedules will be ignored.'\n            print(msg)\n            give_warning(ghenv.Component, msg)\n\n        # extract the timestep if it exists\n        timestep, has_t_step = 1, False\n        tstep_file = os.path.join(res_folder, 'timestep.txt')\n        if os.path.isfile(tstep_file):  # it's an annual irradiance simulation\n            with open(tstep_file) as tf:\n                timestep = int(tf.readline())\n            has_t_step = True\n\n        # parse the sun-up-hours\n        sun_up_hours = [int(h * timestep) for h in sun_up_hours]\n\n        # create the header that will be used for all of the data collections\n        aper = AnalysisPeriod(timestep=timestep)\n        if 'direct_sun_hours' in res_folder:\n            head = Header(Time(), 'hr', aper)\n        elif has_t_step:\n            head = Header(Irradiance(), 'W/m2', aper)\n        else:\n            head = Header(Illuminance(), 'lux', aper)\n        dgp_head = Header(Fraction(), 'fraction', aper, metadata={'type': 'Daylight Glare Probability (DGP)'})\n\n        # create the data collections from the .ill files\n        data = []\n        for grid_info, p_filt in zip(grids, pt_filter):\n            grid_id = grid_info['full_id']\n            ill_file = os.path.join(res_folder, '%s.ill' % grid_id)\n            dgp_file = os.path.join(res_folder, '%s.dgp' % grid_id)\n            if os.path.isfile(dgp_file):\n                data_list = file_to_data(dgp_file, p_filt, sun_up_hours, dgp_head, timestep, grid_id)\n            else:\n                data_list = file_to_data(ill_file, p_filt, sun_up_hours, head, timestep, grid_id)\n            data.append(data_list)\n        data = list_to_data_tree(data)\n", 
  "category": "HB-Radiance", 
  "name": "HB Annual Results to Data", 
  "description": "Import the hourly illuminance or irradiance results of an annual daylight or irradiance\nstudy to a list of data collections.\n_\nThe resulting data collections can be visulized using the ladybug components or\ndeconstructed for detailed analysis with native Grasshopper math components.\n-"
}